{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://www.kaggle.com/datasets/vagifa/ethereum-frauddetection-dataset\n",
    "\n",
    "https://www.kaggle.com/code/soheiltehranipour/how-to-detect-fraud-in-crypto"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "About Dataset\n",
    "Context\n",
    "\n",
    "This dataset contains rows of known fraud and valid transactions made over Ethereum, a type of cryptocurrency. This dataset is imbalanced, so keep that in mind when modelling\n",
    "Content\n",
    "\n",
    "Here is a description of the rows of the dataset:\n",
    "\n",
    "    Index: the index number of a row\n",
    "\n",
    "    Address: the address of the ethereum account\n",
    "\n",
    "    FLAG: whether the transaction is fraud or not\n",
    "\n",
    "    Avg min between sent tnx: Average time between sent transactions for account in minutes\n",
    "\n",
    "    Avg_min_between_received_tnx: Average time between received transactions for account in minutes\n",
    "\n",
    "    Time_Diff_between_first_and_last(Mins): Time difference between the first and last transaction\n",
    "\n",
    "    Sent_tnx: Total number of sent normal transactions\n",
    "\n",
    "    Received_tnx: Total number of received normal transactions\n",
    "\n",
    "    Number_of_Created_Contracts: Total Number of created contract transactions\n",
    "\n",
    "    Unique_Received_From_Addresses: Total Unique addresses from which account received transactions\n",
    "\n",
    "    Unique_Sent_To_Addresses20: Total Unique addresses from which account sent transactions\n",
    "\n",
    "    Min_Value_Received: Minimum value in Ether ever received\n",
    "\n",
    "    Max_Value_Received: Maximum value in Ether ever received\n",
    "\n",
    "    Avg_Value_Received5Average value in Ether ever received\n",
    "\n",
    "    Min_Val_Sent: Minimum value of Ether ever sent\n",
    "\n",
    "    Max_Val_Sent: Maximum value of Ether ever sent\n",
    "\n",
    "    Avg_Val_Sent: Average value of Ether ever sent\n",
    "\n",
    "    Min_Value_Sent_To_Contract: Minimum value of Ether sent to a contract\n",
    "\n",
    "    Max_Value_Sent_To_Contract: Maximum value of Ether sent to a contract\n",
    "\n",
    "    Avg_Value_Sent_To_Contract: Average value of Ether sent to contracts\n",
    "\n",
    "    Total_Transactions(Including_Tnx_to_Create_Contract): Total number of transactions\n",
    "\n",
    "    Total_Ether_Sent:Total Ether sent for account address\n",
    "\n",
    "    Total_Ether_Received: Total Ether received for account address\n",
    "\n",
    "    Total_Ether_Sent_Contracts: Total Ether sent to Contract addresses\n",
    "\n",
    "    Total_Ether_Balance: Total Ether Balance following enacted transactions\n",
    "\n",
    "    Total_ERC20_Tnxs: Total number of ERC20 token transfer transactions\n",
    "\n",
    "    ERC20_Total_Ether_Received: Total ERC20 token received transactions in Ether\n",
    "\n",
    "    ERC20_Total_Ether_Sent: Total ERC20token sent transactions in Ether\n",
    "\n",
    "    ERC20_Total_Ether_Sent_Contract: Total ERC20 token transfer to other contracts in Ether\n",
    "\n",
    "    ERC20_Uniq_Sent_Addr: Number of ERC20 token transactions sent to Unique account addresses\n",
    "\n",
    "    ERC20_Uniq_Rec_Addr: Number of ERC20 token transactions received from Unique addresses\n",
    "\n",
    "    ERC20_Uniq_Rec_Contract_Addr: Number of ERC20token transactions received from Unique contract addresses\n",
    "\n",
    "    ERC20_Avg_Time_Between_Sent_Tnx: Average time between ERC20 token sent transactions in minutes\n",
    "\n",
    "    ERC20_Avg_Time_Between_Rec_Tnx: Average time between ERC20 token received transactions in minutes\n",
    "\n",
    "    ERC20_Avg_Time_Between_Contract_Tnx: Average time ERC20 token between sent token transactions\n",
    "\n",
    "    ERC20_Min_Val_Rec: Minimum value in Ether received from ERC20 token transactions for account\n",
    "\n",
    "    ERC20_Max_Val_Rec: Maximum value in Ether received from ERC20 token transactions for account\n",
    "\n",
    "    ERC20_Avg_Val_Rec: Average value in Ether received from ERC20 token transactions for account\n",
    "\n",
    "    ERC20_Min_Val_Sent: Minimum value in Ether sent from ERC20 token transactions for account\n",
    "\n",
    "    ERC20_Max_Val_Sent: Maximum value in Ether sent from ERC20 token transactions for account\n",
    "\n",
    "    ERC20_Avg_Val_Sent: Average value in Ether sent from ERC20 token transactions for account\n",
    "\n",
    "    ERC20_Uniq_Sent_Token_Name: Number of Unique ERC20 tokens transferred\n",
    "\n",
    "    ERC20_Uniq_Rec_Token_Name: Number of Unique ERC20 tokens received\n",
    "\n",
    "    ERC20_Most_Sent_Token_Type: Most sent token for account via ERC20 transaction\n",
    "\n",
    "    ERC20_Most_Rec_Token_Type: Most received token for account via ERC20 transactions\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, auc, classification_report\n",
    "\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/ethereum-frauddetection-dataset/transaction_dataset.csv', index_col=0)\n",
    "df.sample(3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# drop first two columns (Index, Adress)\n",
    "df = df.iloc[:,2:]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pycaret.classification import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "setup(df,target=\"FLAG\",session_id=85)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "compare_models()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for col in df:print(f'{col} : {len(df[col].unique())}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.select_dtypes(include=['float','int']).describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['FLAG'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.pie(df, values=df['FLAG'].value_counts().values, names=df['FLAG'].value_counts() ,\n",
    "             title='Target distribution of being Fraud or not', color_discrete_sequence=px.colors.sequential.RdBu)\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Percentage of non-fraudulent instances : {len(df.loc[df[\"FLAG\"]==0])/len(df[\"FLAG\"])*100}')\n",
    "print(f'Percentage of fraudulent instances : {len(df.loc[df[\"FLAG\"]==1])/len(df[\"FLAG\"])*100}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Turn object variables into 'category' dtype for more computation efficiency\n",
    "categories = df.select_dtypes('O').columns.astype('category')\n",
    "df[categories]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Drop the two categorical features\n",
    "df.drop(df[categories], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Replace missings of numerical variables with median\n",
    "df.fillna(df.median(), inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Filtering the features with 0 variance\n",
    "no_var = df.var() == 0\n",
    "df.var()[no_var]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Drop features with 0 variance --- these features will not help in the performance of the model\n",
    "df.drop(df.var()[no_var].index, axis = 1, inplace = True)\n",
    "print(df.var())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)]=True\n",
    "with sns.axes_style('white'):\n",
    "    fig, ax = plt.subplots(figsize=(60,60))\n",
    "    sns.heatmap(corr,  mask=mask, annot=True, cmap='CMRmap', center=0, linewidths=0.1, square=True,annot_kws={\"size\": 16})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "soretd_corr=corr.sort_values(by=['FLAG'],key=abs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "soretd_corr"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corr['min val sent']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "drop = ['total transactions (including tnx to create contract',\n",
    "        'total ether sent contracts',\n",
    "        'max val sent to contract',\n",
    "        ' ERC20 avg val rec',\n",
    "        ' ERC20 avg val rec',\n",
    "        ' ERC20 max val rec',\n",
    "        ' ERC20 min val rec',\n",
    "        ' ERC20 uniq rec contract addr',\n",
    "        'max val sent',\n",
    "        ' ERC20 avg val sent',\n",
    "        ' ERC20 min val sent',\n",
    "        ' ERC20 max val sent',\n",
    "        ' Total ERC20 tnxs',\n",
    "        'avg value sent to contract',\n",
    "        'Unique Sent To Addresses',\n",
    "        'Unique Received From Addresses',\n",
    "        'total ether received',\n",
    "        ' ERC20 uniq sent token name',\n",
    "        'min value received',\n",
    "        'min val sent',\n",
    "        ' ERC20 uniq rec addr' ]\n",
    "df.drop(drop, axis=1, inplace=True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Recheck the Correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)]=True\n",
    "with sns.axes_style('white'):\n",
    "    fig, ax = plt.subplots(figsize=(18,18))\n",
    "    sns.heatmap(corr,  mask=mask, annot=True, cmap='CMRmap', center=0, linewidths=0.1, square=True,annot_kws={\"size\": 8})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "columns = df.columns\n",
    "columns\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Some features present a small distribution\n",
    "for i in df.columns[1:]:\n",
    "    if len(df[i].value_counts()) < 10:\n",
    "        print(f'The column {i} has the following distribution: \\n{df[i].value_counts()}')\n",
    "        print('======================================')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "drops = ['min value sent to contract', ' ERC20 uniq sent addr.1']\n",
    "df.drop(drops, axis=1, inplace=True)\n",
    "print(df.shape)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y = df.iloc[:, 0]\n",
    "X = df.iloc[:, 1:]\n",
    "print(X.shape, y.shape)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split into training (80%) and testing set (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc_train = sc.fit_transform(X_train)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sc_df = pd.DataFrame(sc_train, columns=X_train.columns)\n",
    "sc_df\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "print(f'Shape of the training before SMOTE: {sc_train.shape, y_train.shape}')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_tr_resample, y_tr_resample = oversample.fit_resample(sc_train, y_train)\n",
    "print(f'Shape of the training after SMOTE: {x_tr_resample.shape, y_tr_resample.shape}')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Target distribution before SMOTE\n",
    "non_fraud = 0\n",
    "fraud = 0\n",
    "\n",
    "for i in y_train:\n",
    "    if i == 0:\n",
    "        non_fraud +=1\n",
    "    else:\n",
    "        fraud +=1\n",
    "\n",
    "# Target distribution after SMOTE\n",
    "no = 0\n",
    "yes = 1\n",
    "\n",
    "for j in y_tr_resample:\n",
    "    if j == 0:\n",
    "        no +=1\n",
    "    else:\n",
    "        yes +=1\n",
    "\n",
    "\n",
    "print(f'BEFORE OVERSAMPLING \\n \\tNon-frauds: {non_fraud} \\n \\tFauds: {fraud}')\n",
    "print(f'AFTER OVERSAMPLING \\n \\tNon-frauds: {no} \\n \\tFauds: {yes}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LR = LogisticRegression(random_state=42)\n",
    "LR.fit(x_tr_resample, y_tr_resample)\n",
    "\n",
    "# Transform test features\n",
    "sc_test = sc.transform(X_test)\n",
    "\n",
    "preds = LR.predict(sc_test)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(y_test.shape)\n",
    "y_test.value_counts()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(classification_report(y_test, preds))\n",
    "print(confusion_matrix(y_test, preds))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "Considering the confusion matrix:\n",
    "\n",
    "    LR model, correctly identified 367 (TP) of FRAUD cases, out of 422 (P).\n",
    "    LR model flagged as FRAUD 712 (FP) out of 1547, when this cases were actually NON-FRAUD\n",
    "\n",
    "Dealing with a fraud detection scenario, we care more about the transactions that were actualy FRAUDS, but which were treated as NON-FRAUD by our model (FN - 55) TYPE II ERROR\n",
    "\n",
    "Therby, let's try to increase the recall using other methods.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "Random Forest Classifier\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(random_state=42)\n",
    "RF.fit(x_tr_resample, y_tr_resample)\n",
    "preds_RF = RF.predict(sc_test)\n",
    "\n",
    "print(classification_report(y_test, preds_RF))\n",
    "print(confusion_matrix(y_test, preds_RF))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "The RF classifier seems to produce more efective results\n",
    "\n",
    "    Both FP and FN are reduced considerably increasing the recall & precision\n",
    "    Using RF, the model fails to detect 24 FRAUD cases.\n",
    "\n",
    "Let's see if we can increase these results.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "XGB Classifier\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xgb_c = xgb.XGBClassifier(random_state=42)\n",
    "xgb_c.fit(x_tr_resample, y_tr_resample)\n",
    "preds_xgb = xgb_c.predict(sc_test)\n",
    "\n",
    "print(classification_report(y_test, preds_xgb))\n",
    "print(confusion_matrix(y_test, preds_xgb))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "The results of XGBClassifier shows that its doing slightly better than the RF when it comes to NON-FRAUD transactions, flagging 19 cases as fraud when they were actually non-fraud.\n",
    "\n",
    "Wen it comes to identifiying FRAUDS, XGBClassifier missed 19 transactions out of 422, suggesting the best recall score.\n",
    "\n",
    "Considering that, the XGBClassifier is the choice that we want.\n",
    "\n",
    "Let's see if we can improve these results.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "Hyperparameters tuning for XGB Classifier\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "params_grid = {'learning_rate':[0.01, 0.1, 0.5],\n",
    "              'n_estimators':[100,200],\n",
    "              'subsample':[0.5, 0.9],\n",
    "               'max_depth':[3,4],\n",
    "               'colsample_bytree':[0.3,0.7]}\n",
    "\n",
    "grid = GridSearchCV(estimator=xgb_c, param_grid=params_grid, scoring='recall', cv = 10, verbose = 0)\n",
    "\n",
    "grid.fit(x_tr_resample, y_tr_resample)\n",
    "print(f'Best params found for XGBoost are: {grid.best_params_}')\n",
    "print(f'Best recall obtained by the best params: {grid.best_score_}')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Best params found for XGBoost are: {'colsample_bytree': 0.7, 'learning_rate': 0.5, 'max_depth': 4, 'n_estimators': 200, 'subsample': 0.9}\n",
    "Best recall obtained by the best params: 0.9849451237123328\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "preds_best_xgb = grid.best_estimator_.predict(sc_test)\n",
    "print(classification_report(y_test, preds_best_xgb))\n",
    "print(confusion_matrix(y_test, preds_best_xgb))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting AUC for untuned XGB Classifier\n",
    "probs = xgb_c.predict_proba(sc_test)\n",
    "pred = probs[:,1]\n",
    "fpr, tpr, threshold = roc_curve(y_test, pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title('ROC for tuned XGB Classifier')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0,1], [0,1], 'r--')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
