{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# About Dataset\n",
    "## Context\n",
    "This dataset contains rows of known fraud and valid transactions made over Ethereum, a type of cryptocurrency. This dataset is imbalanced, so keep that in mind when modelling\n",
    "\n",
    "## Content\n",
    "Here is a description of the rows of the dataset:\n",
    "\n",
    "- Index: the index number of a row\n",
    "- Address: the address of the ethereum account\n",
    "- FLAG: whether the transaction is fraud or not\n",
    "- Avg min between sent tnx: Average time between sent transactions for account in minutes\n",
    "- Avg min between received tnx: Average time between received transactions for account in minutes\n",
    "- Time Diff between first and_last (Mins): Time difference between the first and last transaction\n",
    "- Sent_tnx: Total number of sent normal transactions\n",
    "- Received_tnx: Total number of received normal transactions\n",
    "- NumberofCreated_Contracts: Total Number of created contract transactions\n",
    "- UniqueReceivedFrom_Addresses: Total Unique addresses from which account received transaction\n",
    "- UniqueSentTo_Addresses20: Total Unique addresses from which account sent transactions\n",
    "- MinValueReceived: Minimum value in Ether ever received\n",
    "- MaxValueReceived: Maximum value in Ether ever received\n",
    "- AvgValueReceived5Average value in Ether ever received\n",
    "- MinValSent: Minimum value of Ether ever sent\n",
    "- MaxValSent: Maximum value of Ether ever sent\n",
    "- AvgValSent: Average value of Ether ever sent\n",
    "- MinValueSentToContract: Minimum value of Ether sent to a contract\n",
    "- MaxValueSentToContract: Maximum value of Ether sent to a contract\n",
    "- AvgValueSentToContract: Average value of Ether sent to contracts\n",
    "- TotalTransactions(IncludingTnxtoCreate_Contract): Total number of transactions\n",
    "- TotalEtherSent:Total Ether sent for account address\n",
    "- TotalEtherReceived: Total Ether received for account address\n",
    "- TotalEtherSent_Contracts: Total Ether sent to Contract addresses\n",
    "- TotalEtherBalance: Total Ether Balance following enacted transactions\n",
    "- TotalERC20Tnxs: Total number of ERC20 token transfer transactions\n",
    "- ERC20TotalEther_Received: Total ERC20 token received transactions in Ether\n",
    "- ERC20TotalEther_Sent: Total ERC20token sent transactions in Ether\n",
    "- ERC20TotalEtherSentContract: Total ERC20 token transfer to other contracts in Ether\n",
    "- ERC20UniqSent_Addr: Number of ERC20 token transactions sent to Unique account addresses\n",
    "- ERC20UniqRec_Addr: Number of ERC20 token transactions received from Unique addresses\n",
    "- ERC20UniqRecContractAddr: Number of ERC20token transactions received from Unique contract addresses\n",
    "- ERC20AvgTimeBetweenSent_Tnx: Average time between ERC20 token sent transactions in minutes\n",
    "- ERC20AvgTimeBetweenRec_Tnx: Average time between ERC20 token received transactions in minutes\n",
    "- ERC20AvgTimeBetweenContract_Tnx: Average time ERC20 token between sent token transactions\n",
    "- ERC20MinVal_Rec: Minimum value in Ether received from ERC20 token transactions for account\n",
    "- ERC20MaxVal_Rec: Maximum value in Ether received from ERC20 token transactions for account\n",
    "- ERC20AvgVal_Rec: Average value in Ether received from ERC20 token transactions for account\n",
    "- ERC20MinVal_Sent: Minimum value in Ether sent from ERC20 token transactions for account\n",
    "- ERC20MaxVal_Sent: Maximum value in Ether sent from ERC20 token transactions for account\n",
    "- ERC20AvgVal_Sent: Average value in Ether sent from ERC20 token transactions for account\n",
    "- ERC20UniqSentTokenName: Number of Unique ERC20 tokens transferred\n",
    "- RC20UniqRecTokenName: Number of Unique ERC20 tokens received\n",
    "- ERC20MostSentTokenType: Most sent token for account via ERC20 transaction\n",
    "- ERC20MostRecTokenType: Most received token for account via ERC20 transactions"
   ],
   "metadata": {
    "id": "cytKDF1Ck5Kk"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Libraries"
   ],
   "metadata": {
    "id": "cgSpi7uRlK90"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ny6D9dMFku0i",
    "ExecuteTime": {
     "end_time": "2024-02-17T16:59:48.766558800Z",
     "start_time": "2024-02-17T16:59:46.968330800Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, auc, classification_report, ConfusionMatrixDisplay, average_precision_score, precision_recall_curve\n",
    "import pickle\n",
    "\n",
    "\n",
    "# DNN\n",
    "from keras.models import Sequential\n",
    "from keras import initializers, regularizers\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow import random"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Set the random seed for reproducibility\n",
    "random.set_seed(42)"
   ],
   "metadata": {
    "id": "3OY6wno-37FG",
    "ExecuteTime": {
     "end_time": "2024-02-17T15:53:24.023489500Z",
     "start_time": "2024-02-17T15:53:23.956487200Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Google Drive"
   ],
   "metadata": {
    "id": "DYQq4UnhlrAz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-AA_fQYdlWZ5",
    "outputId": "f6128615-5a61-422a-a5bd-aedfe04d0e17",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.957487900Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Dataset"
   ],
   "metadata": {
    "id": "fsfKFqUwlnp2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "filename = 'transaction_dataset.csv'"
   ],
   "metadata": {
    "id": "jecvjIDrlP1W",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.958487400Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Count dataset number of lines to inform the dataset size first\n",
    "def count_dataset_rows(file_name):\n",
    "    fp = open(file_name,'r')\n",
    "    for line_count, line in enumerate(fp):\n",
    "        pass\n",
    "    return line_count\n",
    "\n",
    "file_line_count = count_dataset_rows(filename)\n",
    "print('file_line_count for transaction_dataset.csv: ', file_line_count)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BfSrxtjklgeZ",
    "outputId": "bbc460c5-18eb-47b0-a0bf-795ba4bc775a",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.959486900Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(filename, index_col=0)\n",
    "print(df.shape)\n",
    "df.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "N5DYxS6Blinn",
    "outputId": "ff0c2e15-4e95-4d8b-e83d-c87e96ca2f55",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.960486800Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Ommit first two columns (Index, Address)\n",
    "df = df.iloc[:,2:]"
   ],
   "metadata": {
    "id": "XYWEEkXamK-N",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.961487Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing"
   ],
   "metadata": {
    "id": "nqS5hV7amM6I"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df.info()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CjA5Tz6AmOrr",
    "outputId": "d3ba29c8-caae-4b58-ed93-96a85aec72fd",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.962487800Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Turn object variables into 'category' dtype for more computation efficiency\n",
    "categories = df.select_dtypes('O').columns.astype('category')\n",
    "df[categories]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "I6oL04jBmQpY",
    "outputId": "8bd1ce8c-3d7b-485d-cb38-85c77ff83ceb",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.964487300Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Inspect numericals\n",
    "numericals = df.select_dtypes(include=['float','int']).columns\n",
    "df[numericals].describe()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "dUpbE650oKiO",
    "outputId": "17979562-f005-48da-d6d4-b10791650f1a",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.965487600Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Inspect features variance\n",
    "df[numericals].var()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kcg6X5a5oNB-",
    "outputId": "6e20ca65-9f85-42f3-ad89-7b81fe172a9f",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.967488100Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Inspect target distribution\n",
    "print(df['FLAG'].value_counts())\n",
    "\n",
    "pie, ax = plt.subplots(figsize=[15,10])\n",
    "labels = ['Non-fraud', 'Fraud']\n",
    "colors = ['#f9ae35', '#f64e38']\n",
    "plt.pie(x = df['FLAG'].value_counts(), autopct='%.2f%%', explode=[0.02]*2, labels=labels, pctdistance=0.5, textprops={'fontsize': 14}, colors = colors)\n",
    "plt.title('Target distribution')\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 881
    },
    "id": "DVC8yw7YoOu-",
    "outputId": "93bcc7c8-3521-47bd-c39a-06cba98dc817",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.968488Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Correlation matrix\n",
    "corr = df.corr(numeric_only=True)\n",
    "\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)]=True\n",
    "with sns.axes_style('white'):\n",
    "    fig, ax = plt.subplots(figsize=(18,10))\n",
    "    sns.heatmap(corr,  mask=mask, annot=False, cmap='CMRmap', center=0, square=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "u_O3ef-QoQAM",
    "outputId": "4c5e5ee1-5922-4cf5-e5a7-c45bb8b52f41",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.970487300Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Cleaning\n",
    "\n",
    "Check dataset imbalance, normal distributions, outliers and correlations of the between features are important because those can affect the performance of the model."
   ],
   "metadata": {
    "id": "1tlVLe4foRdK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Visualize missings pattern of the dataframe\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.heatmap(df.isnull(), cbar=False)\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "id": "rSu7ZrV2oSwr",
    "outputId": "728bfc1d-9b10-4af9-9cbd-86a6b0efe027",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.971487200Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Drop the two categorical features\n",
    "df.drop(df[categories], axis=1, inplace=True)"
   ],
   "metadata": {
    "id": "ajsZsC6CorHT",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.973488900Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Replace missings of numerical variables with median\n",
    "df.fillna(df.median(), inplace=True)"
   ],
   "metadata": {
    "id": "rv5sBWc5oskf",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.974487800Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Visualize missings pattern of the dataframe\n",
    "print(df.shape)\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.heatmap(df.isnull(), cbar=False)\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "id": "eoumQGlWoumb",
    "outputId": "cb7f12cf-01f5-4e20-c0bb-a101b3904281",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.975487300Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Investigating the variance of the features, it was observed that there are some features with a variance = 0"
   ],
   "metadata": {
    "id": "7flBRCaCowX7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Filtering the features with 0 variance\n",
    "no_var = df.var() == 0\n",
    "print(df.var()[no_var])\n",
    "print('\\n')\n",
    "\n",
    "# Drop features with 0 variance --- these features will not help in the performance of the model\n",
    "df.drop(df.var()[no_var].index, axis = 1, inplace = True)\n",
    "print(df.var())\n",
    "print(df.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fhIE4hdioxfT",
    "outputId": "09179a7b-6f71-4384-dc38-8ce1ea96bc2f",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.977487Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df.info()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jRu5QUo7oy9k",
    "outputId": "4ce5931c-fecc-440f-b5a5-2af3458a5dac",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.978487600Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Recheck the Correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)]=True\n",
    "with sns.axes_style('white'):\n",
    "    fig, ax = plt.subplots(figsize=(18,10))\n",
    "    sns.heatmap(corr,  mask=mask, annot=False, cmap='CMRmap', center=0, linewidths=0.1, square=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HwBFAiC7o0Uk",
    "outputId": "2d654c80-cffe-4c41-9bbd-30158f84320c",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.979487600Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "drop = ['total transactions (including tnx to create contract', 'total ether sent contracts', 'max val sent to contract', ' ERC20 avg val rec',\n",
    "        ' ERC20 avg val rec',' ERC20 max val rec', ' ERC20 min val rec', ' ERC20 uniq rec contract addr', 'max val sent', ' ERC20 avg val sent',\n",
    "        ' ERC20 min val sent', ' ERC20 max val sent', ' Total ERC20 tnxs', 'avg value sent to contract', 'Unique Sent To Addresses',\n",
    "        'Unique Received From Addresses', 'total ether received', ' ERC20 uniq sent token name', 'min value received', 'min val sent', ' ERC20 uniq rec addr' ]\n",
    "df.drop(drop, axis=1, inplace=True)"
   ],
   "metadata": {
    "id": "vYsOq_Uxo17O",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.980487900Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Recheck the Correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)]=True\n",
    "with sns.axes_style('white'):\n",
    "    fig, ax = plt.subplots(figsize=(18,10))\n",
    "    sns.heatmap(corr,  mask=mask, annot=False, cmap='CMRmap', center=0, linewidths=0.1, square=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "FcjV4qOao3YZ",
    "outputId": "56dd8fca-58ad-49c1-e0e2-c4209baf71b9",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.981487900Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "columns = df.columns\n",
    "columns"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bBqJ2-Mco42n",
    "outputId": "3b743364-ecb2-4526-c1c8-91b7c79a5597",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.982487300Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Investigate the distribution of our features using boxplots\n",
    "b=20\n",
    "\n",
    "fig, axes = plt.subplots(6, 3, figsize=(14, 14), constrained_layout =True)\n",
    "plt.subplots_adjust(wspace = 0.7, hspace=0.8)\n",
    "plt.suptitle(\"Distribution of features\",y=0.95, size=18, weight='bold')\n",
    "\n",
    "ax = sns.boxplot(ax = axes[0,0], data=df, x=columns[1])\n",
    "ax.set_title(f'Distribution of {columns[1]}')\n",
    "\n",
    "ax1 = sns.boxplot(ax = axes[0,1], data=df, x=columns[2])\n",
    "ax1.set_title(f'Distribution of {columns[2]}')\n",
    "\n",
    "ax2 = sns.boxplot(ax = axes[0,2], data=df, x=columns[3])\n",
    "ax2.set_title(f'Distribution of {columns[3]}')\n",
    "\n",
    "ax3 = sns.boxplot(ax = axes[1,0], data=df, x=columns[4])\n",
    "ax3.set_title(f'Distribution of {columns[4]}')\n",
    "\n",
    "ax4 = sns.boxplot(ax = axes[1,1], data=df, x=columns[5])\n",
    "ax4.set_title(f'Distribution of {columns[5]}')\n",
    "\n",
    "ax5 = sns.boxplot(ax = axes[1,2], data=df, x=columns[6])\n",
    "ax5.set_title(f'Distribution of {columns[6]}')\n",
    "\n",
    "ax6 = sns.boxplot(ax = axes[2,0], data=df, x=columns[7])\n",
    "ax6.set_title(f'Distribution of {columns[7]}')\n",
    "\n",
    "ax7 = sns.boxplot(ax = axes[2,1], data=df, x=columns[8])\n",
    "ax7.set_title(f'Distribution of {columns[8]}')\n",
    "\n",
    "ax8 = sns.boxplot(ax = axes[2,2], data=df, x=columns[9])\n",
    "ax8.set_title(f'Distribution of {columns[9]}')\n",
    "\n",
    "ax9 = sns.boxplot(ax = axes[3,0], data=df, x=columns[10])\n",
    "ax9.set_title(f'Distribution of {columns[10]}')\n",
    " \n",
    "ax10 = sns.boxplot(ax = axes[3,1], data=df, x=columns[11])\n",
    "ax10.set_title(f'Distribution of {columns[11]}')\n",
    "\n",
    "ax11 = sns.boxplot(ax = axes[3,2], data=df, x=columns[12])\n",
    "ax11.set_title(f'Distribution of {columns[12]}')\n",
    " \n",
    "ax12 = sns.boxplot(ax = axes[4,0], data=df, x=columns[13])\n",
    "ax12.set_title(f'Distribution of {columns[13]}')\n",
    " \n",
    "ax13 = sns.boxplot(ax = axes[4,1], data=df, x=columns[14])\n",
    "ax13.set_title(f'Distribution of {columns[14]}')\n",
    " \n",
    "ax14 = sns.boxplot(ax = axes[4,2], data=df, x=columns[15])\n",
    "ax14.set_title(f'Distribution of {columns[15]}')\n",
    " \n",
    "ax15 = sns.boxplot(ax = axes[5,0], data=df, x=columns[16])\n",
    "ax15.set_title(f'Distribution of {columns[16]}')\n",
    " \n",
    "ax16 = sns.boxplot(ax = axes[5,1], data=df, x=columns[17])\n",
    "ax16.set_title(f'Distribution of {columns[17]}')\n",
    " \n",
    "ax17 = sns.boxplot(ax = axes[5,2], data=df, x=columns[18])\n",
    "ax17.set_title(f'Distribution of {columns[18]}')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CSjdrbqio7Al",
    "outputId": "99f13358-fd88-4255-c98b-781d9f40f54e",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.984487600Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Some features present a small distribution\n",
    "for i in df.columns[1:]:\n",
    "    if len(df[i].value_counts()) < 10:\n",
    "        print(f'The column {i} has the following distribution: \\n{df[i].value_counts()}')\n",
    "        print('======================================')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rXSY2tdyo-FR",
    "outputId": "7716af51-8937-4640-8456-384918167f43",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.985487900Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Based on the output, it can be observed that the values of these two variables are mosty 0s. Thus, both features will be discarded since they will not be helpful for our model"
   ],
   "metadata": {
    "id": "Op7n6WXbpC5p"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "drops = ['min value sent to contract', ' ERC20 uniq sent addr.1']\n",
    "df.drop(drops, axis=1, inplace=True)\n",
    "print(df.shape)\n",
    "df.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "-1VincExpBHl",
    "outputId": "d3e50f7c-1750-40e5-b78a-b19c5b5b3e9c",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.986486900Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Preparation\n",
    "\n",
    "Preprocess the data into training and validation datasets to be used for modelling of different algorithms."
   ],
   "metadata": {
    "id": "V99fZIXZpHd6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "y = df.iloc[:, 0]\n",
    "X = df.iloc[:, 1:]\n",
    "print(X.shape, y.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yH_AerW0pgqt",
    "outputId": "319143aa-d500-4f9f-82d8-451fbabbefc7",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.987487Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Split into training (80%) and testing set (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XVdiJpMepgms",
    "outputId": "6dd6d673-b8ae-4a85-dd2f-3e5f691a4fe1",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.988487100Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Normalize the training features\n",
    "norm = PowerTransformer()\n",
    "norm_train_f = norm.fit_transform(X_train)"
   ],
   "metadata": {
    "id": "vpgjeHwUsu-m",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.989487100Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Transform test features\n",
    "norm_test_f = norm.transform(X_test)"
   ],
   "metadata": {
    "id": "9wa7UO5Am-Wa",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.990486700Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "norm_df = pd.DataFrame(norm_train_f, columns=X_train.columns)\n",
    "norm_df"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "id": "YqG0CGwlsvaL",
    "outputId": "efc4e0b4-812a-46ef-f1d3-3cfa043ee75d",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.990486700Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Distribution of features after log transformation\n",
    "\n",
    "b=20\n",
    "\n",
    "fig, axes = plt.subplots(6, 3, figsize=(14, 14), constrained_layout =True)\n",
    "plt.subplots_adjust(wspace = 0.7, hspace=0.8)\n",
    "axes[-1, -1].axis('off') # hide axes\n",
    "axes[-1, -2].axis('off') # hide axes\n",
    "plt.suptitle(\"Distribution of features after log\",y=0.95, family='Sherif', size=18, weight='bold')\n",
    " \n",
    "ax = sns.boxplot(ax = axes[0,0], data=norm_df, x=norm_df.columns[0])\n",
    "ax.set_title(f'Distribution of {norm_df.columns[0]}')\n",
    " \n",
    "ax1 = sns.boxplot(ax = axes[0,1], data=norm_df, x=norm_df.columns[1])\n",
    "ax1.set_title(f'Distribution of {norm_df.columns[1]}')\n",
    " \n",
    "ax2 = sns.boxplot(ax = axes[0,2], data=norm_df, x=norm_df.columns[2])\n",
    "ax2.set_title(f'Distribution of {norm_df.columns[2]}')\n",
    " \n",
    "ax3 = sns.boxplot(ax = axes[1,0], data=norm_df, x=norm_df.columns[3])\n",
    "ax3.set_title(f'Distribution of {norm_df.columns[3]}')\n",
    " \n",
    "ax4 = sns.boxplot(ax = axes[1,1], data=norm_df, x=norm_df.columns[4])\n",
    "ax4.set_title(f'Distribution of {norm_df.columns[4]}')\n",
    " \n",
    "ax5 = sns.boxplot(ax = axes[1,2], data=norm_df, x=norm_df.columns[5])\n",
    "ax5.set_title(f'Distribution of {norm_df.columns[5]}')\n",
    " \n",
    "ax6 = sns.boxplot(ax = axes[2,0], data=norm_df, x=norm_df.columns[6])\n",
    "ax6.set_title(f'Distribution of {norm_df.columns[6]}')\n",
    " \n",
    "ax7 = sns.boxplot(ax = axes[2,1], data=norm_df, x=norm_df.columns[7])\n",
    "ax7.set_title(f'Distribution of {norm_df.columns[7]}')\n",
    " \n",
    "ax8 = sns.boxplot(ax = axes[2,2], data=norm_df, x=norm_df.columns[8])\n",
    "ax8.set_title(f'Distribution of {norm_df.columns[8]}')\n",
    " \n",
    "ax9 = sns.boxplot(ax = axes[3,0], data=norm_df, x=norm_df.columns[9])\n",
    "ax9.set_title(f'Distribution of {norm_df.columns[9]}')\n",
    "\n",
    "ax10 = sns.boxplot(ax = axes[3,1], data=norm_df, x=norm_df.columns[10])\n",
    "ax10.set_title(f'Distribution of {norm_df.columns[10]}')\n",
    " \n",
    "ax11 = sns.boxplot(ax = axes[3,2], data=norm_df, x=norm_df.columns[11])\n",
    "ax11.set_title(f'Distribution of {norm_df.columns[11]}')\n",
    " \n",
    "ax12 = sns.boxplot(ax = axes[4,0], data=norm_df, x=norm_df.columns[12])\n",
    "ax12.set_title(f'Distribution of {norm_df.columns[12]}')\n",
    " \n",
    "ax13 = sns.boxplot(ax = axes[4,1], data=norm_df, x=norm_df.columns[13])\n",
    "ax13.set_title(f'Distribution of {norm_df.columns[13]}')\n",
    " \n",
    "ax14 = sns.boxplot(ax = axes[4,2], data=norm_df, x=norm_df.columns[14])\n",
    "ax14.set_title(f'Distribution of {norm_df.columns[14]}')\n",
    " \n",
    "ax15 = sns.boxplot(ax = axes[5,0], data=norm_df, x=norm_df.columns[15])\n",
    "ax15.set_title(f'Distribution of {norm_df.columns[15]}')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "miVCX9l5sx63",
    "outputId": "2e2eb56b-de5d-4ef4-f49e-27575ce5b6d9",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.991486800Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Imbalance"
   ],
   "metadata": {
    "id": "q1hmMw2Esziz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "oversample = SMOTE()\n",
    "print(f'Shape of the training before SMOTE: {norm_train_f.shape, y_train.shape}')\n",
    "\n",
    "x_tr_resample, y_tr_resample = oversample.fit_resample(norm_train_f, y_train)\n",
    "print(f'Shape of the training after SMOTE: {x_tr_resample.shape, y_tr_resample.shape}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_OnrJAjus1Qw",
    "outputId": "7e053bac-bc33-437d-8a6e-158136cbe110",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.992486800Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Target distribution before SMOTE\n",
    "non_fraud = 0\n",
    "fraud = 0\n",
    "\n",
    "for i in y_train:\n",
    "    if i == 0:\n",
    "        non_fraud +=1\n",
    "    else:\n",
    "        fraud +=1\n",
    "\n",
    "# Target distribution after SMOTE\n",
    "no = 0\n",
    "yes = 1\n",
    "\n",
    "for j in y_tr_resample:\n",
    "    if j == 0:\n",
    "        no +=1\n",
    "    else:\n",
    "        yes +=1\n",
    "\n",
    "\n",
    "print(f'BEFORE OVERSAMPLING \\n \\tNon-frauds: {non_fraud} \\n \\tFrauds: {fraud}')\n",
    "print(f'AFTER OVERSAMPLING \\n \\tNon-frauds: {no} \\n \\tFrauds: {yes}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Ww7-VAPs2Ua",
    "outputId": "a1803e25-1d7a-4080-fe29-4c07b560b0ff",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.993486300Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Modelling"
   ],
   "metadata": {
    "id": "217Nv4H2s5H5"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression"
   ],
   "metadata": {
    "id": "y7OrCJIks-RA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "LR = LogisticRegression(random_state=42)\n",
    "LR.fit(x_tr_resample, y_tr_resample)\n",
    "\n",
    "preds = LR.predict(norm_test_f)"
   ],
   "metadata": {
    "id": "lJnreLPEs3yd",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.994486900Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(y_test.shape)\n",
    "y_test.value_counts()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9hyuCQ64tBVq",
    "outputId": "09c8d90c-7751-4007-bf1a-a1ee33a419cb",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.994486900Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(classification_report(y_test, preds))\n",
    "\n",
    "# create the confusion matrix\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "print(cm)\n",
    "\n",
    "# create the display object\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=LR.classes_)\n",
    "\n",
    "# plot the confusion matrix\n",
    "disp.plot()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 657
    },
    "id": "NRIziP-ptCjc",
    "outputId": "572f077b-cb9f-450c-bbeb-b63646ce1088",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.995487100Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Considering the confusion matrix:\n",
    " - LR model, correctly identified 373 (TP) of FRAUD cases, out of 422 (P).\n",
    " - LR model flagged as FRAUD 171 (FP) out of 1547, when this cases were actually NON-FRAUD\n",
    " \n",
    "\n",
    "Dealing with a fraud detection scenario, we care more about the transactions that were actualy FRAUDS, but which were treated as NON-FRAUD by our model (FN - 49) TYPE II ERROR\n",
    "\n",
    "Thereby, let's try to increase the recall using other methods.\n"
   ],
   "metadata": {
    "id": "AGYHSeaPtY5r"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest"
   ],
   "metadata": {
    "id": "iHJW6tTrulEe"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "RF = RandomForestClassifier(random_state=42)\n",
    "RF.fit(x_tr_resample, y_tr_resample)\n",
    "preds_RF = RF.predict(norm_test_f)\n",
    "\n",
    "print(classification_report(y_test, preds_RF))\n",
    "\n",
    "# create the confusion matrix\n",
    "cm = confusion_matrix(y_test, preds_RF)\n",
    "print(cm)\n",
    "\n",
    "# create the display object\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=LR.classes_)\n",
    "\n",
    "# plot the confusion matrix\n",
    "disp.plot()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 657
    },
    "id": "rwyFpmyFtEa3",
    "outputId": "9b7fbe36-1d0c-4c4c-8d20-0a218348f51d",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.996486800Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The RF classifier seems to produce more efective results\n",
    " - Both FP and FN are reduced considerably increasing the recall & precision\n",
    " - Using RF, the model fails to detect 20 FRAUD cases. \n",
    "\n",
    "\n",
    "Let's see if we can increase these results."
   ],
   "metadata": {
    "id": "qVmBZEtSu18q"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## XGBClassifier (XGBoost)\n",
    "\n",
    "XGBClassifier is a class in scikit-learn that provides an API for the XGBoost algorithm."
   ],
   "metadata": {
    "id": "CKHcDmSbu3hw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "xgb_c = xgb.XGBClassifier(random_state=42)\n",
    "xgb_c.fit(x_tr_resample, y_tr_resample)\n",
    "preds_xgb = xgb_c.predict(norm_test_f)\n",
    "\n",
    "print(classification_report(y_test, preds_xgb))\n",
    "\n",
    "# create the confusion matrix\n",
    "cm = confusion_matrix(y_test, preds_xgb)\n",
    "print(cm)\n",
    "\n",
    "# create the display object\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=LR.classes_)\n",
    "\n",
    "# plot the confusion matrix\n",
    "disp.plot()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 657
    },
    "id": "pzOYHUEJu3Gi",
    "outputId": "781350ad-68e1-435e-e78c-e9f9622e0054",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.997487300Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## XGB Classifier with Hyperparameters"
   ],
   "metadata": {
    "id": "NSsNp-Mbv0bW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "params_grid = {'learning_rate':[0.01, 0.1, 0.5],\n",
    "              'n_estimators':[100,200],\n",
    "              'subsample':[0.3, 0.5, 0.9],\n",
    "               'max_depth':[2,3,4],\n",
    "               'colsample_bytree':[0.3,0.5,0.7]}\n",
    "\n",
    "grid = GridSearchCV(estimator=xgb_c, param_grid=params_grid, scoring='recall', cv = 10, verbose = 0)\n",
    "\n",
    "grid.fit(x_tr_resample, y_tr_resample)\n",
    "print(f'Best params found for XGBoost are: {grid.best_params_}')\n",
    "print(f'Best recall obtained by the best params: {grid.best_score_}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8E6F7JcWv6Pz",
    "outputId": "06d88706-d0a1-4066-ccea-5c6872efe953",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.998487Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "preds_best_xgb = grid.best_estimator_.predict(norm_test_f)\n",
    "\n",
    "print(classification_report(y_test, preds_best_xgb))\n",
    "\n",
    "# create the confusion matrix\n",
    "cm = confusion_matrix(y_test, preds_best_xgb)\n",
    "print(cm)\n",
    "\n",
    "# create the display object\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=LR.classes_)\n",
    "\n",
    "# plot the confusion matrix\n",
    "disp.plot()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 657
    },
    "id": "0byBwGsQv9y5",
    "outputId": "f5d4f454-7bb2-4d1d-be50-2f10cdaf7079",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.999487500Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Based on the above outputs, the confusion matrix shows no improvement, the results are very similar with those obtained by the untuned model."
   ],
   "metadata": {
    "id": "so4qADL2v5jj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Plotting AUC for untuned XGB Classifier\n",
    "probs = xgb_c.predict_proba(norm_test_f)\n",
    "pred = probs[:,1]\n",
    "fpr, tpr, threshold = roc_curve(y_test, pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title('ROC for tuned XGB Classifier')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0,1], [0,1], 'r--')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "id": "51OjeSH7wF6n",
    "outputId": "2d7f3e10-67fd-4505-c911-de81befe98e2",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:23.999487500Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deep Neural Network (DNN)"
   ],
   "metadata": {
    "id": "sdRrpii0wTiG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualizations\n",
    "\n",
    "Make some visualizations for displaying the results based on previous module tutorials.\n",
    "\n",
    "* Loss and Accuracy Plot: A line plot that has 2 lines that shows the training of the modelling process.\n",
    "* Confusion Matrix: A table used to evaluate the performance of a classification model. It shows the number of true positives, false positives, true negatives, and false negatives. You can use the scikit-learn library to calculate and plot the confusion matrix.\n",
    "* ROC (Receiver Operating Characteristic) Curve: A plot that shows the performance of a binary classifier as the discrimination threshold is varied. You can use the scikit-learn library to calculate the ROC curve and plot it using matplotlib.\n",
    "* Precision-Recall Curve: A plot of the precision (positive predictive value) versus the recall (sensitivity) for different threshold values. You can use the scikit-learn library to calculate the precision-recall curve and plot it using matplotlib.\n"
   ],
   "metadata": {
    "id": "WSdRId-1whA-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def show_model_performance(norm_test_f, y_test, model):\n",
    "  # Evaluate the model\n",
    "  lost, accuracy = model.evaluate(norm_test_f, y_test, verbose=0)\n",
    "  print('Loss:', lost)\n",
    "  print('Accuracy:', accuracy)\n",
    "\n",
    "def show_loss_and_accuracy_line_plot(history):\n",
    "  # Plot the loss and accuracy over epochs\n",
    "  plt.plot(history.history['loss'])\n",
    "  plt.plot(history.history['val_loss'])\n",
    "  plt.title('Model loss')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "  plt.show()\n",
    "\n",
    "  plt.plot(history.history['accuracy'])\n",
    "  plt.plot(history.history['val_accuracy'])\n",
    "  plt.title('Model accuracy')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "  plt.show()\n",
    "\n",
    "def show_confusion_matrix(y_test, model, y_pred_binary):\n",
    "  print(classification_report(y_test, y_pred_binary))\n",
    "  # create the confusion matrix\n",
    "  cm = confusion_matrix(y_test, y_pred_binary)\n",
    "  print(cm)\n",
    "\n",
    "  # create the display object\n",
    "  disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "  # plot the confusion matrix\n",
    "  disp.plot()\n",
    "\n",
    "def show_roc_curve_plot(y_test, y_pred):\n",
    "  # Compute ROC curve and ROC area for each class\n",
    "  fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "  roc_auc = auc(fpr, tpr)\n",
    "\n",
    "  # Plot ROC curve\n",
    "  plt.figure(figsize=(8, 6))\n",
    "  plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "  plt.plot([0, 1], [0, 1], 'k--')\n",
    "  plt.xlim([0.0, 1.0])\n",
    "  plt.ylim([0.0, 1.05])\n",
    "  plt.xlabel('False Positive Rate')\n",
    "  plt.ylabel('True Positive Rate')\n",
    "  plt.title('Receiver Operating Characteristic')\n",
    "  plt.legend(loc=\"lower right\")\n",
    "  plt.show()\n",
    "\n",
    "def show_precision_recall_curve_plot(y_test, y_pred):\n",
    "  # Compute Precision-Recall curve and average precision for each class\n",
    "  precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "  average_precision = average_precision_score(y_test, y_pred)\n",
    "\n",
    "  # Plot Precision-Recall curve\n",
    "  plt.figure(figsize=(8, 6))\n",
    "  plt.step(recall, precision, color='b', alpha=0.2, where='post')\n",
    "  plt.fill_between(recall, precision, alpha=0.2, color='b')\n",
    "  plt.xlabel('Recall')\n",
    "  plt.ylabel('Precision')\n",
    "  plt.ylim([0.0, 1.05])\n",
    "  plt.xlim([0.0, 1.0])\n",
    "  plt.title('Precision-Recall curve: AP={0:0.2f}'.format(average_precision))\n",
    "  plt.show()"
   ],
   "metadata": {
    "id": "krLrXd1SwrnO",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:24.001487300Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model 1"
   ],
   "metadata": {
    "id": "xdFQQ2ZqwXrT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Number of neurons. No harm in changing the numbers, no guidelines here.\n",
    "L1 = 64 # First hidden layer neurons\n",
    "L2 = 32 # Second hidden layer neurons\n",
    "\n",
    "\n",
    "# Activation functions\n",
    "activation_function = 'relu'\n",
    "activation_function2 = 'relu'\n",
    "output_activation_function = 'sigmoid' # Multi-class = softmax, Binary = sigmoid, continuous = linear\n",
    "\n",
    "# Number of outputs\n",
    "# You need to know your columns, for example, you only prdicting the value is_malicious, so here only one value.\n",
    "no_of_output = 1\n",
    "\n",
    "# Initialize object\n",
    "model = Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "model.add(Dense(L1, input_dim=x_tr_resample.shape[1], activation=activation_function))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(Dense(L2, activation=activation_function2))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(no_of_output,activation=output_activation_function))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_tr_resample, y_tr_resample, validation_split=0.2, epochs=24, batch_size=128, verbose=1)\n",
    "\n",
    "y_pred = model.predict(norm_test_f)\n",
    "\n",
    "# Convert predicted probabilities to binary predictions\n",
    "y_pred_binary = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "show_model_performance(norm_test_f, y_test, model)\n",
    "show_loss_and_accuracy_line_plot(history)\n",
    "show_confusion_matrix(y_test, model, y_pred_binary)\n",
    "show_roc_curve_plot(y_test, y_pred_binary)\n",
    "show_precision_recall_curve_plot(y_test, y_pred_binary)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zeGbzlq2wWZw",
    "outputId": "81df3b18-9734-4af9-f0ad-f1af714a7db3",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:24.001487300Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DNN Model 2\n",
    "\n",
    "* Added another Hidden Layer and Dropout Layer.\n",
    "* Increased the number of neurons in current layers.\n",
    "* Additionally, added early stopping to prevent overtraining."
   ],
   "metadata": {
    "id": "apOQpDmFxO_y"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Number of neurons. No harm in changing the numbers, no guidelines here.\n",
    "L1 = 128 # First hidden layer neurons\n",
    "L2 = 64 # Second hidden layer neurons\n",
    "L3 = 32 # Third hidden layer neurons\n",
    "\n",
    "# Activation functions\n",
    "activation_function = 'relu'\n",
    "activation_function2 = 'relu'\n",
    "activation_function3 = 'relu'\n",
    "output_activation_function = 'sigmoid' # Multi-class = softmax, Binary = sigmoid, continuous = linear\n",
    "\n",
    "# Number of outputs\n",
    "# You need to know your columns, for example, you only prdicting the value is_malicious, so here only one value.\n",
    "no_of_output = 1\n",
    "\n",
    "# Initialize object\n",
    "model = Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "model.add(Dense(L1, input_dim=x_tr_resample.shape[1], activation=activation_function))\n",
    "\n",
    "# Dropout Layer\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(Dense(L2, activation=activation_function2))\n",
    "\n",
    "# Dropout Layer\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(Dense(L3, activation=activation_function3))\n",
    "\n",
    "# Dropout Layer\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(no_of_output,activation=output_activation_function,kernel_regularizer=regularizers.l2(0.01)))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_tr_resample, y_tr_resample, validation_split=0.2, epochs=24, batch_size=128, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(norm_test_f)\n",
    "\n",
    "# Convert predicted probabilities to binary predictions\n",
    "y_pred_binary = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "show_model_performance(norm_test_f, y_test, model)\n",
    "show_loss_and_accuracy_line_plot(history)\n",
    "show_confusion_matrix(y_test, model, y_pred_binary)\n",
    "show_roc_curve_plot(y_test, y_pred_binary)\n",
    "show_precision_recall_curve_plot(y_test, y_pred_binary)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jlDlLnYKxQU2",
    "outputId": "6d0d1ac3-b38a-428a-b52e-8dd64511da3e",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:24.002487400Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DNN Model 3\n",
    "\n",
    "* Added neurons of each layer to 256, 128 and 64 respectively.\n",
    "* Added Kernel Initializer GlorotNormal."
   ],
   "metadata": {
    "id": "SodIE6fzxS7e"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Number of neurons. No harm in changing the numbers, no guidelines here.\n",
    "L1 = 256 # First hidden layer neurons\n",
    "L2 = 128 # Second hidden layer neurons\n",
    "L3 = 64 # Third hidden layer neurons\n",
    "\n",
    "# Activation functions\n",
    "activation_function = 'relu'\n",
    "activation_function2 = 'relu'\n",
    "activation_function3 = 'relu'\n",
    "output_activation_function = 'sigmoid' # Multi-class = softmax, Binary = sigmoid, continuous = linear\n",
    "\n",
    "# Number of outputs\n",
    "# You need to know your columns, for example, you only prdicting the value is_malicious, so here only one value.\n",
    "no_of_output = 1\n",
    "\n",
    "# Initialize object\n",
    "model = Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "model.add(Dense(L1, input_dim=x_tr_resample.shape[1], activation=activation_function))\n",
    "\n",
    "# Dropout Layer\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(Dense(L2, activation=activation_function2))\n",
    "\n",
    "# Dropout Layer\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(Dense(L3, activation=activation_function3, kernel_initializer=initializers.GlorotNormal(seed=None), kernel_regularizer=regularizers.l2(0.01)))\n",
    "\n",
    "# Dropout Layer\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(no_of_output,activation=output_activation_function,kernel_regularizer=regularizers.l2(0.01)))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_tr_resample, y_tr_resample, validation_split=0.2, epochs=24, batch_size=128, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(norm_test_f)\n",
    "\n",
    "# Convert predicted probabilities to binary predictions\n",
    "y_pred_binary = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "show_model_performance(norm_test_f, y_test, model)\n",
    "show_loss_and_accuracy_line_plot(history)\n",
    "show_confusion_matrix(y_test, model, y_pred_binary)\n",
    "show_roc_curve_plot(y_test, y_pred_binary)\n",
    "show_precision_recall_curve_plot(y_test, y_pred_binary)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "BGKXktwUxSt0",
    "outputId": "e8e3f4d0-7c80-4b73-aa8f-8418eff94acf",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:24.003487200Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DNN Model 4\n",
    "Adding even more neurons, layers with initializers and regularizers to each layer. Additionally, tried not to remove outlier by z-score and IQR to check whether remove outliers or 'noises' is the root cause of overfitting. Increase the learning rate (0.001, 0.01) on each layer. Increse Dropout rate (0.3)"
   ],
   "metadata": {
    "id": "6ErAWL0sxc7Z"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Number of neurons. No harm in changing the numbers, no guidelines here.\n",
    "L1 = 1024 # First hidden layer neurons\n",
    "L2 = 512 # Second hidden layer neurons\n",
    "L3 = 256 # Third hidden layer neurons\n",
    "L4 = 128 # Fourth hidden layer neurons\n",
    "L5 = 64  # Fifth hidden layer neurons\n",
    "\n",
    "# Activation functions\n",
    "activation_function = 'relu'\n",
    "activation_function2 = 'relu'\n",
    "activation_function3 = 'relu'\n",
    "output_activation_function = 'sigmoid' # Multi-class = softmax, Binary = sigmoid, continuous = linear\n",
    "\n",
    "# Number of outputs\n",
    "# You need to know your columns, for example, you only prdicting the value is_malicious, so here only one value.\n",
    "no_of_output = 1\n",
    "\n",
    "# Initialize object\n",
    "model = Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "model.add(Dense(L1, input_dim=x_tr_resample.shape[1], activation=activation_function, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None), kernel_regularizer=regularizers.l2(0.01)))\n",
    "\n",
    "# Dropout Layer\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(Dense(L2, activation=activation_function2, kernel_initializer=initializers.GlorotNormal(seed=None), kernel_regularizer=regularizers.l2(0.01)))\n",
    "\n",
    "# Dropout Layer\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(Dense(L3, activation=activation_function3, kernel_initializer=initializers.GlorotNormal(seed=None), kernel_regularizer=regularizers.l2(0.01)))\n",
    "\n",
    "# Dropout Layer\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(Dense(L4, activation=activation_function3, kernel_initializer=initializers.GlorotNormal(seed=None), kernel_regularizer=regularizers.l2(0.01)))\n",
    "\n",
    "# Dropout Layer\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(Dense(L5, activation=activation_function3, kernel_initializer=initializers.GlorotNormal(seed=None), kernel_regularizer=regularizers.l2(0.01)))\n",
    "\n",
    "# Dropout Layer\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(no_of_output, activation=output_activation_function, kernel_initializer=initializers.GlorotNormal(seed=None), kernel_regularizer=regularizers.l2(0.01)))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_tr_resample, y_tr_resample, validation_split=0.2, epochs=24, batch_size=128, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(norm_test_f)\n",
    "\n",
    "# Convert predicted probabilities to binary predictions\n",
    "y_pred_binary = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "show_model_performance(norm_test_f, y_test, model)\n",
    "show_loss_and_accuracy_line_plot(history)\n",
    "show_confusion_matrix(y_test, model, y_pred_binary)\n",
    "show_roc_curve_plot(y_test, y_pred_binary)\n",
    "show_precision_recall_curve_plot(y_test, y_pred_binary)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fKWeqEhCxk66",
    "outputId": "ed45c90e-4bc4-4589-e5ce-f9948106ff86",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:24.004487Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DNN Model 5 (Hyperparameters)\n",
    "\n",
    "Introduce DNN Grid Search Hyperparameter.\n",
    "\n",
    "There are several reasons why Grid Search Hyperparameters are introduced:\n",
    "\n",
    "* Automation: Manually tuning hyperparameters can be a time-consuming and error-prone process. Grid Search Hyperparameters automates this process and finds the best combination of hyperparameters to improve the model's performance.\n",
    "\n",
    "* Performance improvement: Hyperparameters have a significant impact on a model's performance. Grid Search Hyperparameters can help in selecting the best combination of hyperparameters that can lead to improved performance.\n",
    "\n",
    "* Generalization: Hyperparameters that are optimized for a specific dataset may not work well on other datasets. Grid Search Hyperparameters can help in finding the optimal hyperparameters that work well on different datasets.\n",
    "\n",
    "* Efficiency: Grid Search Hyperparameters is an efficient approach to finding the best hyperparameters, as it systematically explores all possible combinations of hyperparameters.\n",
    "\n",
    "GridSearchCV function tries to intelligently speed up the hyperparameter search process by removing the other possibilities when tuning hyperparameters. It uses a technique called \"grid search\" to exhaustively search through all the possible combinations of hyperparameters, but it uses a smart approach to search only through the combinations that are likely to be useful.\n",
    "\n",
    "It does this by performing a cross-validation on each combination of hyperparameters and only selecting those combinations that perform the best. It then continues the search using these combinations until it finds the best hyperparameters.\n",
    "\n",
    "However, despite its intelligent search approach, GridSearchCV can still be computationally expensive, especially when the search space is large. It is important to carefully choose the hyperparameters to search and limit the search space to avoid unnecessary computations.\n",
    "\n",
    "Have dropout rate to disable dropout layer to test possibilities."
   ],
   "metadata": {
    "id": "5yduhFQCxn16"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Function to create model with given parameters\n",
    "def create_model(optimizer='adam', activation='relu', loss='binary_crossentropy', metrics=['accuracy'], \n",
    "                 L1=1024, L2=512, L3=256, L4=128, L5=64, dropout_rate=0.3, learning_rate=0.1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(L1, input_dim=x_tr_resample.shape[1], activation=activation, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(L2, activation=activation, kernel_initializer=initializers.GlorotNormal(seed=None)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(L3, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(L4, activation=activation, kernel_initializer=initializers.GlorotNormal(seed=None), kernel_regularizer=regularizers.l2(learning_rate)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(L5, activation=activation, kernel_initializer=initializers.GlorotNormal(seed=None), kernel_regularizer=regularizers.l2(learning_rate)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(no_of_output, activation='sigmoid'))\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    return model"
   ],
   "metadata": {
    "id": "n_DzbGpzCEoR",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:24.005487100Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print('y.shape:\\n\\n\\n', y.shape)\n",
    "print('X.shape:\\n\\n\\n', X.shape)\n",
    "print('x_tr_resample.shape:\\n\\n\\n', x_tr_resample.shape)\n",
    "print('y_tr_resample.shape:\\n\\n\\n', y_tr_resample.shape)\n",
    "\n",
    "# Define the EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Create KerasClassifier object for GridSearchCV\n",
    "model = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "\n",
    "# Define grid search parameters\n",
    "optimizers = ['adam'] # 'rmsprop', \n",
    "activations = ['relu']\n",
    "losses = ['binary_crossentropy'] # , 'mean_squared_error'\n",
    "metrics = ['accuracy'] # , ['precision', 'recall']\n",
    "epochs = [48]\n",
    "batches = [128]\n",
    "l1 = [1024]\n",
    "l2 = [512]\n",
    "l3 = [256]\n",
    "l4 = [128]\n",
    "l5 = [64]\n",
    "dropout_rates = [0.1, 0.2, 0.3, 0.4]\n",
    "learning_rates = [0.01]\n",
    "\n",
    "param_grid = dict(optimizer=optimizers, activation=activations, loss=losses, metrics=metrics, epochs=epochs, batch_size=batches, \n",
    "                L1=l1, L2=l2, L3=l3, L4=l4, L5=l5, dropout_rate=dropout_rates, learning_rate=learning_rates)\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "\n",
    "# Fit the grid search with EarlyStopping callback\n",
    "grid.fit(x_tr_resample, y_tr_resample)\n",
    "\n",
    "print(f'Best params found for DNN are: {grid.best_params_}')\n",
    "print(f'Best recall obtained by the best params: {grid.best_score_}')\n",
    "\n",
    "preds_best_dnn = grid.best_estimator_.predict(norm_test_f)\n",
    "\n",
    "# print(classification_report(y_test, preds_best_dnn))\n",
    "# print(confusion_matrix(y_test, preds_best_dnn))\n",
    "# plot_confusion_matrix(grid.best_estimator_, norm_test_f, y_test)\n",
    "\n",
    "print(classification_report(y_test, preds_best_dnn))\n",
    "\n",
    "# create the confusion matrix\n",
    "cm = confusion_matrix(y_test, preds_best_dnn)\n",
    "print(cm)\n",
    "\n",
    "# create the display object\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=LR.classes_)\n",
    "\n",
    "# plot the confusion matrix\n",
    "disp.plot()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "WHmgyv-sxuoj",
    "outputId": "8d150835-90a3-4921-e2d6-cfcff983816f",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:24.006487300Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Final Model"
   ],
   "metadata": {
    "id": "1CfPRUcLETSk"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Function to create model with given parameters\n",
    "def create_model2(optimizer='adam', activation='relu', loss='binary_crossentropy', metrics=['accuracy'], \n",
    "                 L1=1024, L2=512, L3=256, L4=128, L5=64, dropout_rate=0.3, learning_rate=0.1):\n",
    "    print('optimizer: ', optimizer)\n",
    "    print('activation: ', activation)\n",
    "    print('loss: ', loss)\n",
    "    print('metrics: ', metrics)\n",
    "    print('L1: ', L1)\n",
    "    print('L2: ', L2)\n",
    "    print('L3: ', L3)\n",
    "    print('L4: ', L4)\n",
    "    print('L5: ', L5)\n",
    "    print('dropout_rate: ', dropout_rate)\n",
    "    print('learning_rate: ', learning_rate)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(L1, input_dim=x_tr_resample.shape[1], activation=activation, kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(L2, activation=activation, kernel_initializer=initializers.GlorotNormal(seed=None)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(L3, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(L4, activation=activation, kernel_initializer=initializers.GlorotNormal(seed=None), kernel_regularizer=regularizers.l2(learning_rate)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(L5, activation=activation, kernel_initializer=initializers.GlorotNormal(seed=None), kernel_regularizer=regularizers.l2(learning_rate)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    return model"
   ],
   "metadata": {
    "id": "iD-MxA_uX2be",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:24.007486900Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Best params found for DNN are: {'L1': 1024, 'L2': 512, 'L3': 256, 'L4': 128, 'L5': 64, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.1, 'epochs': 48,\n",
    "#                                 'learning_rate': 0.01, 'loss': 'binary_crossentropy', 'metrics': 'accuracy', 'optimizer': 'adam'}\n",
    "model = create_model('adam', 'relu', 'binary_crossentropy', 'accuracy', 1024, 512, 256, 128, 64, 0.1, 0.01)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_tr_resample, y_tr_resample, validation_split=0.2, epochs=48, batch_size=128, verbose=1)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(norm_test_f)\n",
    "\n",
    "# Convert predicted probabilities to binary predictions\n",
    "y_pred_binary = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "show_model_performance(norm_test_f, y_test, model)\n",
    "show_loss_and_accuracy_line_plot(history)\n",
    "show_confusion_matrix(y_test, model, y_pred_binary)\n",
    "show_roc_curve_plot(y_test, y_pred_binary)\n",
    "show_precision_recall_curve_plot(y_test, y_pred_binary)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oJ-VUJllEU4J",
    "outputId": "7e711393-4226-4200-a373-9da23d8be027",
    "ExecuteTime": {
     "start_time": "2024-02-17T15:53:24.008488200Z"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
